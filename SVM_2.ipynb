{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "527e8fc0-e00f-4553-8cb9-f018037c0972",
   "metadata": {},
   "source": [
    "# Answer 1\n",
    "\n",
    "Polynomial functions and kernel functions are both used in machine learning algorithms to transform data into a higher-dimensional space in order to make it easier to classify or analyze.\n",
    "\n",
    "Polynomial functions are a type of function that involve raising an input variable to various powers and multiplying by coefficients. Polynomial functions are commonly used in regression analysis, where they can be used to fit a curve to a set of data points. In machine learning, polynomial functions can be used as a basis function to transform data into a higher-dimensional space.\n",
    "\n",
    "Kernel functions, on the other hand, are a general class of functions that take two inputs and return a scalar value. In machine learning, kernel functions are used to compute the similarity between two data points in a feature space. The kernel function essentially measures the degree of similarity between two inputs, and this similarity metric is used to determine how close or far apart the inputs are in the transformed feature space.\n",
    "\n",
    "In many cases, polynomial functions can be used as kernel functions in machine learning algorithms. This is because polynomial functions can be expressed as a dot product of two vectors in a higher-dimensional space. Specifically, the polynomial kernel function is defined as:\n",
    "### K(x, y) = (x^T y + c)^d\n",
    "\n",
    "where x and y are input vectors, d is the degree of the polynomial, and c is a constant term. This kernel function computes the similarity between two inputs in a higher-dimensional feature space without explicitly transforming the data into that space.\n",
    "\n",
    "In summary, while polynomial functions and kernel functions are different types of functions, they are related in that polynomial functions can be used as kernel functions in machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6ddc50-d3f6-4a7c-ae48-73c1be3952ab",
   "metadata": {},
   "source": [
    "# Answer 2\n",
    "\n",
    "To implement a support vector machine (SVM) with a polynomial kernel in Python using Scikit-learn, you can follow these steps:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4436474-b870-4b85-a623-45d2bc50a09b",
   "metadata": {},
   "source": [
    "### Step 1: Import the necessary libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06ab1b4a-94ac-44d9-8f10-518a646e533f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcc4bed-631a-4ae0-9046-a83e40a5e947",
   "metadata": {},
   "source": [
    "### Step 2: Generate a sample dataset for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d76a777d-b42c-4bca-ba42-7425ead5cf65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=100, n_features=10, n_informative=5, n_classes=2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3b19de-708c-471f-a460-b46dfff86a34",
   "metadata": {},
   "source": [
    "### Step 3: Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ef438f5-9b77-4e74-b690-1313697c07de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a64b6dd-6ee9-4d00-9582-3791982a8325",
   "metadata": {},
   "source": [
    "### Step 4: Create an instance of the SVM model with the polynomial kernel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2997d49c-13e6-48c8-a3dd-b97279d6e46a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "poly_svm = SVC(kernel='poly', degree=3, gamma='scale')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c099d234-e713-4e4a-82df-fa8268f8cb7b",
   "metadata": {},
   "source": [
    "In the above code, we have specified the kernel parameter as 'poly' to use the polynomial kernel and the degree parameter as 3 to specify the degree of the polynomial.\n",
    "\n",
    "### Step 5: Fit the model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a8eb3b8-a26c-49cf-93d1-ef9210b08e7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='poly')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_svm.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf20b71-9341-4dbe-af1b-62c0d5a27ec1",
   "metadata": {},
   "source": [
    "### Step 6: Make predictions on the test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c403c2c-72c4-4b96-9810-a64574c82194",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = poly_svm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e717ae-cd35-49de-b988-92e0608f8cc1",
   "metadata": {},
   "source": [
    "### Step 7: Evaluate the performance of the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5dfe277-616f-490f-adde-eef96f157890",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f34d90b-e388-4472-bda4-abc51bab09e8",
   "metadata": {},
   "source": [
    "In the above code, we have used the accuracy_score function from the metrics module of Scikit-learn to calculate the accuracy of the model.\n",
    "\n",
    "Overall, these steps show how you can implement a support vector machine (SVM) with a polynomial kernel in Python using Scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547c9f07-4798-465a-a922-a5ec5957a745",
   "metadata": {},
   "source": [
    "### Answer 3\n",
    "\n",
    "In Support Vector Regression (SVR), the parameter epsilon is a hyperparameter that controls the trade-off between the flatness of the regression function and the degree to which errors are tolerated in the training data. Specifically, epsilon defines a margin of tolerance around the predicted value, within which errors are not penalized.\n",
    "\n",
    "Increasing the value of epsilon in SVR tends to increase the number of support vectors. This is because as the value of epsilon increases, the flatness of the regression function increases and the degree of error tolerance also increases. As a result, more data points are likely to fall within the margin of tolerance, which in turn leads to more support vectors.\n",
    "\n",
    "The number of support vectors in SVR has a direct impact on the complexity of the model and its ability to generalize to new data. In general, a higher number of support vectors can lead to longer training times and potentially overfitting to the training data. On the other hand, a lower number of support vectors can result in a simpler model that may not capture all of the complex relationships in the data.\n",
    "\n",
    "Therefore, the choice of epsilon should be carefully considered to strike a balance between model complexity and accuracy. In practice, the optimal value of epsilon is often determined through a process of cross-validation or grid search over a range of hyperparameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb087e1-8adc-443e-926e-55ca4d134a51",
   "metadata": {},
   "source": [
    "# Answer 4\n",
    "\n",
    "\n",
    "The performance of Support Vector Regression (SVR) is heavily dependent on the choice of hyperparameters such as the kernel function, C parameter, epsilon parameter, and gamma parameter. In this answer, we will discuss each parameter and explain how it works and when you might want to increase or decrease its value.\n",
    "\n",
    "* Kernel Function: The choice of kernel function determines the mapping of the input data to a high-dimensional feature space. The kernel function is specified using the kernel hyperparameter in the SVR object. Scikit-learn provides several options for kernel functions, such as linear, polynomial, and radial basis function (RBF). The choice of kernel function depends on the nature of the data and the problem at hand. In general, the RBF kernel is a good default choice and works well in many scenarios.\n",
    "* C Parameter: The C parameter controls the trade-off between model complexity and training error. It is specified using the C hyperparameter in the SVR object. A smaller value of C will result in a wider margin and a simpler model, while a larger value of C will result in a narrower margin and a more complex model. Increasing the value of C can lead to overfitting, while decreasing the value of C can lead to underfitting. You might want to increase the value of C if the model is underfitting, and decrease the value of C if the model is overfitting.\n",
    "* Epsilon Parameter: The epsilon parameter determines the width of the margin around the predicted value within which errors are not penalized. It is specified using the epsilon hyperparameter in the SVR object. A larger value of epsilon will allow for more error in the model, while a smaller value of epsilon will make the model more sensitive to errors. You might want to increase the value of epsilon if the model is too sensitive to noise, and decrease the value of epsilon if the model is not sensitive enough to noise.\n",
    "* Gamma Parameter: The gamma parameter determines the width of the Gaussian kernel for the RBF kernel function. It is specified using the gamma hyperparameter in the SVR object. A larger value of gamma will result in a narrower kernel and a more complex model, while a smaller value of gamma will result in a wider kernel and a simpler model. Increasing the value of gamma can lead to overfitting, while decreasing the value of gamma can lead to underfitting. You might want to increase the value of gamma if the model is underfitting, and decrease the value of gamma if the model is overfitting.\n",
    "In general, the choice of hyperparameters in Support Vector Regression (SVR) can have a significant impact on the performance of the model. It is highly recommended to test different values of these hyperparameters using techniques such as cross-validation and grid search to find the optimal combination of hyperparameters for the given problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6fa6e3-9a7d-4530-bc1c-77036523d43c",
   "metadata": {},
   "source": [
    "# Answer 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb1ceac6-581d-48e4-914f-e2c6aa4fafbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2a7a0a7-e6a5-470c-9d0d-e515af704df2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets=load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ea85954-8901-499e-a3ae-128a0c8b7859",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(datasets.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1b13552-b56f-4adf-847a-135045ac22ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1bae3a92-aefc-4ecd-bb7f-d28dee3de252",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data=datasets.data,columns=datasets.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "590df9ac-69a8-4f00-a88c-7c21444c0585",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['target']=datasets.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ae505e60-14c8-4651-94ae-155e8e71f5e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "17b1a57f-c350-4111-bfb9-b483a94c010d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dependdent and independent data\n",
    "\n",
    "x=df.iloc[:,:-1]\n",
    "y=df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dffa57f1-c884-468b-b483-bc67730220a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "145    2\n",
       "146    2\n",
       "147    2\n",
       "148    2\n",
       "149    2\n",
       "Name: target, Length: 150, dtype: int32"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "375a3759-7159-470d-a29e-15ac9afed5b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eb716c78-811a-4488-b806-df77f2e5a4cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d3959e4c-04d8-45f2-b73b-357cf8abae90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "49c78ec4-8ed2-4f1e-9fff-58e9831b51f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ff28c7f8-906b-48ff-bda1-1f0a7483cdf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = svc.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "06f787cf-48a6-4790-95db-d09730dcca39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5a09fa5d-aef7-471b-8898-7798ff802085",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "72e27676-115f-4346-ba10-0a82a8efbcda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV 1/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.708 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=10, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=10, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=10, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=10, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=10, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END .......C=0.1, gamma=10, kernel=rbf;, score=0.708 total time=   0.0s\n",
      "[CV 2/5] END .......C=0.1, gamma=10, kernel=rbf;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END .......C=0.1, gamma=10, kernel=rbf;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END .......C=0.1, gamma=10, kernel=rbf;, score=0.333 total time=   0.0s\n",
      "[CV 5/5] END .......C=0.1, gamma=10, kernel=rbf;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=10, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=10, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=10, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=10, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=10, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END .........C=1, gamma=10, kernel=rbf;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END .........C=1, gamma=10, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 3/5] END .........C=1, gamma=10, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .........C=1, gamma=10, kernel=rbf;, score=0.792 total time=   0.0s\n",
      "[CV 5/5] END .........C=1, gamma=10, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=10, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=10, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=10, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=10, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=10, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ........C=10, gamma=10, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 2/5] END ........C=10, gamma=10, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 3/5] END ........C=10, gamma=10, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ........C=10, gamma=10, kernel=rbf;, score=0.792 total time=   0.0s\n",
      "[CV 5/5] END ........C=10, gamma=10, kernel=rbf;, score=0.917 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['svc_model.joblib']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.1, 1, 10], 'gamma': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=3)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "# 8. Train the tuned classifier on the entire dataset\n",
    "best_svc = grid.best_estimator_\n",
    "X_scaled = scaler.fit_transform(x)\n",
    "best_svc.fit(X_scaled, y)\n",
    "# 9. Save the trained classifier to a file for future use\n",
    "joblib.dump(best_svc, 'svc_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd406b5-c13a-41d8-b67f-aefddbcd7558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b146ad84-5e4c-4ee7-875d-a5e80a531906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a240cdb-26ec-4b56-b8b7-51ae2265824b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "33c0e1f3-f66a-4540-8685-af729019bb0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5125a97-e268-493c-81a5-49695c5a4d2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edfea4f-788d-4525-8b49-69731b11c840",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5624f4-5f03-4d34-b22b-e738a32386e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
