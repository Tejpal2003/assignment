{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56f98381-56ca-46bb-9034-9a3ef6f20136",
   "metadata": {},
   "source": [
    "# ans1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c28696-ed52-42ed-9c06-dfec86e34aef",
   "metadata": {},
   "source": [
    "Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications. There are many different ways to perform web scraping to obtain data from websites. These include using online services, particular API’s or even creating your code for web scraping from scratch. Many large websites, like Google, Twitter, Facebook, StackOverflow, etc. have API’s that allow you to access their data in a structured format. This is the best option, but there are other sites that don’t allow users to access large amounts of data in a structured form or they are simply not that technologically advanced. In that situation, it’s best to use Web Scraping to scrape the website for data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24461b24-b154-460c-a452-93a90725dac3",
   "metadata": {},
   "source": [
    "# Three area where Web Scraping is used to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f1bf38-922c-42d0-b175-9896ca55707d",
   "metadata": {},
   "source": [
    "1. Lead Generation\n",
    "2. Comparison Shopping Sites\n",
    "3. Industry Statistics and Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89d36d6-058e-40cf-aa99-a476f18ce03c",
   "metadata": {},
   "source": [
    "# ans2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35dfc2d-eb2d-48fa-86ea-6a0b56af843a",
   "metadata": {},
   "source": [
    "Some method for web scrapping\n",
    "\n",
    "Beautiful Soup.\n",
    "Requests.\n",
    "Scrapy.\n",
    "Selenium.\n",
    "Playwright.\n",
    "Lxml.\n",
    "Urllib3.\n",
    "MechanicalSoup.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03184e6f-68eb-44e5-b459-67c78dfadc96",
   "metadata": {},
   "source": [
    "# ans3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e06519b-fc2f-4c4c-a714-fd5717f7b2e5",
   "metadata": {},
   "source": [
    "# Beautiful Soup\n",
    "Beautiful Soup is a Python library that makes it easy to scrape information from web pages. It sits atop an HTML or XML parser and provides Pythonic idioms for iterating, searching, and modifying the parse tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38652bbc-49b4-48b4-a227-624f8acda4bc",
   "metadata": {},
   "source": [
    "# Uses of Beautiful Soup\n",
    "The Beautiful Soup library helps with isolating titles and links from webpages. It can extract all of the text from ​HTML tags, and alter the HTML ​in the document with which we’re working."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bafd4e-cc44-49bc-af17-771ad3911915",
   "metadata": {},
   "source": [
    "# ans4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f9c614-44ab-411f-a0d4-d3ca7f8ec759",
   "metadata": {},
   "source": [
    "Flask is a lightweight framework to build websites. We'll use this to parse our collected data and display it as HTML in a new HTML file. The requests module allows us to send http requests to the website we want to scrape. The first line imports the Flask class and the render_template method from the flask library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3508499a-da96-4ad6-9ec6-8d7a21154696",
   "metadata": {},
   "source": [
    "# ans5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b597f59-4bbe-4fde-ba7c-fba29bb27a83",
   "metadata": {},
   "source": [
    "1. Amazon EC2\n",
    "You don’t have to invest in costly physical services. Instead, you can create virtual machines with Amazon EC2 while managing other server features such as ports, security, and storage. Spend less time maintaining your servers and more time on your strategic projects. Invariably, Amazon EC2 is one of the most popular and fastest-growing of the many AWS services.\n",
    "\n",
    "2. Amazon RDS\n",
    "The Amazon Relational Database Service (RDS) was designed to make your infrastructure more user friendly. By using this AWS service, you can create dedicated instances of databases within minutes. Not to mention, these instances can support multiple database engines including SQL Server, SQL, PostgreSQL, and more. Take your time back and stop spending hours maintaining your database servers. Let Amazon RDS do the work for you.\n",
    "\n",
    "3. Amazon Simple Storage Service (S3)\n",
    "We are living in the age of big data. Some call it the incessant data deluge. As a result, we need more storage than ever before. Amazon Simple Storage Service (S3) has come to the rescue. It makes sense why this would be included in our list of the top 10 most used AWS services. It offers a highly secure and redundant file storage service. It also stores data in three data centers within a specific region. And, there’s more. Amazon S3 also offers integrations to help prevent breaches by way of PCI-DSS, HIPAA/HITECH, and FedRAMP. You get data flexibility without almost zero latency.\n",
    "\n",
    "4. Amazon CloudFront\n",
    "This service helps to improve website speed and access to cloud-based data. CloudFront works as a Global Content Delivery Service (CDN) to deliver content efficiently to end users. You’ll notice a significant increase in web page loading speed with this service. It even pulls website static files from data centers throughout the world.\n",
    "\n",
    "5. Amazon VPC\n",
    "If you are ready to isolate your entire IT infrastructure from exposure, then the only way to do it is with Amazon VPS. This service creates a private virtual network that cannot be accessed by anyone or anything except the people and systems you authorize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2526eab5-919e-418a-9f2e-cd3cf119e850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
